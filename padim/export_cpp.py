import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.padim_detector import PaDiMDetector

class PaDiMOnnxWrapper(nn.Module):
    """
    å°† å½’ä¸€åŒ– + ç‰¹å¾æå– + å¤šå°ºåº¦èåˆ + éšæœºé™ç»´ å°è£…æˆä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¨¡å‹
    è¾“å…¥: [1, 3, 112, 112] (RGB, 0~1 float æˆ– 0~255 uint8ï¼Œè½¬ä¸º float)
    è¾“å‡º: [1, 28, 28, 100]
    """
    def __init__(self, feature_extractor, indices):
        super().__init__()
        self.backbone = feature_extractor
        # å°† indices æ³¨å†Œä¸º bufferï¼Œè¿™æ ·å®ƒä¼šè¢«ä¿å­˜ä½†ä¸ä¼šè¢«è§†ä¸ºæ¨¡å‹å‚æ•°
        self.register_buffer('indices', indices)

        # ==========================================
        # ğŸ‘‡ğŸ‘‡ğŸ‘‡ æ–°å¢ï¼šåµŒå…¥å½’ä¸€åŒ–å‚æ•° ğŸ‘‡ğŸ‘‡ğŸ‘‡
        # ==========================================
        # ImageNet æ ‡å‡†å‡å€¼å’Œæ–¹å·® (å¦‚æœä½ çš„è®­ç»ƒæ•°æ®ç”¨çš„æ˜¯è¿™ä¸ª)
        self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))
        self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))


    def forward(self, x):
        # ==========================================
        # ğŸ‘‡ğŸ‘‡ğŸ‘‡ æ–°å¢ï¼šæ¨¡å‹å†…éƒ¨å½’ä¸€åŒ– ğŸ‘‡ğŸ‘‡ğŸ‘‡
        # ==========================================
        # å‡è®¾è¾“å…¥ x æ˜¯ 0~1 çš„ float (C++ ä¼ è¿›æ¥æ—¶åªéœ€ /255.0)
        x = (x - self.mean) / self.std
        
        # 1. æå–ç‰¹å¾ (List of tensors)
        features_list = self.backbone(x)
        
        # 2. å¤šå°ºåº¦èåˆ (Resize & Concat)
        # å‡è®¾ features_list[0] æ˜¯æœ€å¤§çš„ (28x28)
        target_h, target_w = features_list[0].shape[2], features_list[0].shape[3]
        
        resized_features = []
        for f in features_list:
            # åªæœ‰å°ºå¯¸ä¸å¯¹æ—¶æ‰æ’å€¼
            if f.shape[2] != target_h or f.shape[3] != target_w:
                f = F.interpolate(f, size=(target_h, target_w), mode='bilinear', align_corners=False)
            resized_features.append(f)
        
        # [B, C_total, H, W]
        out = torch.cat(resized_features, dim=1)
        
        # 3. ç»´åº¦è½¬æ¢ [B, C, H, W] -> [B, H, W, C]
        # è¿™æ ·åšæ˜¯ä¸ºäº†æ–¹ä¾¿ C++ åç»­è®¡ç®— (H*W ä¸ªåƒç´ å¹¶è¡Œ)
        out = out.permute(0, 2, 3, 1)
        
        # 4. éšæœºé€šé“é€‰æ‹© (é™ç»´)
        # ç›´æ¥åœ¨æ¨¡å‹å†…éƒ¨å®Œæˆï¼ŒC++ å°±ä¸éœ€è¦çŸ¥é“ indices äº†
        if self.indices is not None:
            out = torch.index_select(out, 3, self.indices)
            
        return out

def export_to_cpp(model_dir, output_dir):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    print(f"æ­£åœ¨åŠ è½½ Python æ¨¡å‹: {model_dir}")
    detector = PaDiMDetector(model_dir=model_dir)
    device = torch.device('cpu') # å¯¼å‡ºæ—¶ç”¨ CPU å³å¯
    detector.feature_extractor.to(device)
    
    # ==========================================
    # 1. å¯¼å‡º ONNX æ¨¡å‹ (ResNet + é¢„å¤„ç†)
    # ==========================================
    print("-" * 50)
    print("æ­£åœ¨å¯¼å‡º ONNX æ¨¡å‹...")
    
    indices = detector.indices.cpu() if detector.indices is not None else None
    wrapper = PaDiMOnnxWrapper(detector.feature_extractor, indices)
    wrapper.eval()


    dummy_input = torch.randn(1, 3, 112, 112) 
    
    onnx_path = os.path.join(output_dir, "padim_backbone.onnx")
    
   
    
    torch.onnx.export(
        wrapper,
        dummy_input,
        onnx_path,
        input_names=['input'],
        output_names=['features'],
        opset_version=11,
        dynamic_axes={'input': {0: 'batch_size'}, 'features': {0: 'batch_size'}}
    )
    print(f"âœ… FP32 ONNX æ¨¡å‹å·²ä¿å­˜: {onnx_path}")
    
    # éªŒè¯ä¸€ä¸‹è¾“å‡ºå½¢çŠ¶
    with torch.no_grad():
        out_tensor = wrapper(dummy_input)
        print(f"   æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {out_tensor.shape} (æœŸæœ›: [1, 28, 28, 100])")

    # ==========================================
    # 2. å¯¼å‡ºç»Ÿè®¡å‚æ•° (å‡å€¼ & é€†åæ–¹å·®)
    # ==========================================
    print("-" * 50)
    print("æ­£åœ¨è®¡ç®—å¹¶å¯¼å‡ºç»Ÿè®¡å‚æ•° (.bin)...")
    
    # è·å–å‡å€¼ [H, W, C]
    means = detector.means.cpu().numpy().astype(np.float32)
    
    # è·å–åæ–¹å·®å¹¶è®¡ç®—é€†çŸ©é˜µ [H, W, C, C]
    covs = detector.covs.cpu().numpy().astype(np.float32)
    H, W, C, _ = covs.shape
    
    print("   æ­£åœ¨è®¡ç®—ä¼ªé€†çŸ©é˜µ (è¿™å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´)...")
    # å±•å¹³è®¡ç®—
    covs_flat = covs.reshape(-1, C, C)
    inv_covs_flat = np.linalg.pinv(covs_flat) # ä½¿ç”¨ä¼ªé€†ä¿è¯ç¨³å®šæ€§
    inv_covs = inv_covs_flat.reshape(H, W, C, C).astype(np.float32)
    
    # ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶
    means_path = os.path.join(output_dir, "means.bin")
    inv_covs_path = os.path.join(output_dir, "inv_covs.bin")
    
    means.tofile(means_path)
    inv_covs.tofile(inv_covs_path)
    
    print(f"âœ… å‡å€¼æ–‡ä»¶å·²ä¿å­˜: {means_path} | Size: {means.nbytes / 1024:.2f} KB")
    print(f"âœ… é€†åæ–¹å·®å·²ä¿å­˜: {inv_covs_path} | Size: {inv_covs.nbytes / 1024 / 1024:.2f} MB")
    
    # ==========================================
    # 3. ç”Ÿæˆ C++ é…ç½®æ–‡ä»¶
    # ==========================================
    config_path = os.path.join(output_dir, "config.txt")
    with open(config_path, 'w') as f:
        f.write(f"input_width=112\n")
        f.write(f"input_height=112\n")
        f.write(f"feature_map_h={H}\n")
        f.write(f"feature_map_w={W}\n")
        f.write(f"feature_dim={C}\n")
    print(f"âœ… é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {config_path}")
    
    print("-" * 50)
    print("å¯¼å‡ºå®Œæˆï¼è¯·å°† cpp_model æ–‡ä»¶å¤¹å¤åˆ¶åˆ°ä½ çš„ C++ é¡¹ç›®ä¸­ã€‚")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_dir', type=str, default='./saved_models', help='Pythonæ¨¡å‹è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./cpp_model', help='å¯¼å‡ºè·¯å¾„')
    args = parser.parse_args()
    
    export_to_cpp(args.model_dir, args.output_dir)