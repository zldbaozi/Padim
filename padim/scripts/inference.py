import os
import sys
import time
import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
from PIL import Image
import argparse

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ==========================================
# 1. åŸºç¡€å·¥å…· (è§£å†³ä¸­æ–‡è·¯å¾„é—®é¢˜)
# ==========================================

def cv_imread(path):
    try:
        return cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_COLOR)
    except:
        return None

def cv_imwrite(path, img):
    try:
        ext = os.path.splitext(path)[1] or '.png'
        ok, buf = cv2.imencode(ext, img)
        if ok:
            buf.tofile(path)
            return True
    except:
        pass
    return False

# å®šä¹‰ä¸€ä¸ªåªåš ToTensor å’Œ Normalize çš„ transformï¼Œä¿ç•™åŸå°ºå¯¸
def get_raw_transforms():
    return transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
# ==========================================
# 2. æ¨ç†å¼•æ“ (æ•´å›¾æ¨ç†)
# ==========================================

class PaDiMInferenceEngine:
    def __init__(self, model_dir, device='cuda'):
        from models.padim_detector import PaDiMDetector
        
        print(f"ğŸ—ï¸  åŠ è½½æ¨¡å‹: {model_dir}")
        self.detector = PaDiMDetector(model_dir=model_dir)
        self.device = device
        
        self.transform = transforms.Compose([
            transforms.Resize((112, 112)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])

    def process_folder(self, input_dir, save_dir, threshold=3.0):
        # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(input_dir):
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return
        valid_exts = {'.jpg', '.jpeg', '.png', '.bmp'}
        files = [f for f in os.listdir(input_dir) if os.path.splitext(f)[1].lower() in valid_exts]
        if not files:
            print("âš ï¸ æ–‡ä»¶å¤¹ä¸ºç©º")
            return
        print(f"ğŸš€ å¼€å§‹å¤„ç† {len(files)} å¼ å›¾ç‰‡...")
        os.makedirs(save_dir, exist_ok=True)
        
        # é¢„çƒ­ GPU
        print("ğŸ”¥ æ­£åœ¨é¢„çƒ­ GPU...")
        dummy = torch.randn(1, 3, 112, 112).to(self.device)  # ç¡®ä¿å°ºå¯¸ä¸º 112Ã—112
        for _ in range(5): self.detector.predict(dummy)
        torch.cuda.synchronize()

        t_start = time.perf_counter()
        
        for idx, f in enumerate(files):
            img_path = os.path.join(input_dir, f)
            img_bgr = cv_imread(img_path)
            if img_bgr is None: 
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {img_path}")
                continue
            
            # 1. é¢„å¤„ç†
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(img_rgb)
            input_tensor = self.transform(pil_img).unsqueeze(0).to(self.device)
            
            # 2. æ¨ç†
            amap, score = self.detector.predict(input_tensor)
            score = score[0]
            amap = amap[0]  # (H, W) åŸå§‹å¼‚å¸¸å€¼
            
            # 3. æ‰“å°çŠ¶æ€
            status = "ğŸ”´å¼‚å¸¸" if score > threshold else "ğŸŸ¢æ­£å¸¸"
            print(f"[{idx+1}/{len(files)}] {f} -> {status} (å¾—åˆ†: {score:.2f})")
            
            # ==========================================
            # 4. ç°åº¦çƒ­åŠ›å›¾ç”Ÿæˆ
            # ==========================================
            
            # Resize åˆ°åŸå›¾å¤§å°
            amap_resized = cv2.resize(amap, (img_bgr.shape[1], img_bgr.shape[0]))
            
            # å½’ä¸€åŒ–ç­–ç•¥
            max_val = 4.0  # å›ºå®šé˜ˆå€¼å½’ä¸€åŒ–
            norm_map = np.clip(amap_resized / max_val, 0, 1)
            
            # è½¬ä¸º 8ä½ ç°åº¦å›¾ (0=é»‘, 255=ç™½)
            heatmap_gray = (norm_map * 255).astype(np.uint8)
            
            # ä¿å­˜ç»“æœ
            save_path = os.path.join(save_dir, f)
            cv_imwrite(save_path, heatmap_gray)

        t_end = time.perf_counter()
        avg_time = (t_end - t_start) / len(files) * 1000
        print(f"âœ… å…¨éƒ¨å®Œæˆ | å¹³å‡è€—æ—¶: {avg_time:.2f} ms/å¼ ")


# ==========================================
# 3. ä¸»å…¥å£
# ==========================================

def main(args):
    try:
        # åˆå§‹åŒ–å¼•æ“
        engine = PaDiMInferenceEngine(args.model_dir)
        
        # æ‰§è¡Œæ¨ç†
        engine.process_folder(
            input_dir=args.test_data, 
            save_dir=args.save_dir, 
            threshold=args.threshold
        )
            
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="PaDiM Inference (Full Image)")
    
    parser.add_argument('--model_dir', type=str, required=True, help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--test_data', type=str, required=True, help='æµ‹è¯•æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--save_dir', type=str, default='./results', help='ç»“æœä¿å­˜è·¯å¾„')
    parser.add_argument('--threshold', type=float, default=3.0, help='å¼‚å¸¸é˜ˆå€¼')
    
    args = parser.parse_args()
    main(args)