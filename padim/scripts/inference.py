import os
import sys
import time
import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
from PIL import Image
import argparse

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ==========================================
# 1. åŸºç¡€å·¥å…· (è§£å†³ä¸­æ–‡è·¯å¾„é—®é¢˜)
# ==========================================

def cv_imread(path):
    try:
        return cv2.imdecode(np.fromfile(path, dtype=np.uint8), cv2.IMREAD_COLOR)
    except:
        return None

def cv_imwrite(path, img):
    try:
        ext = os.path.splitext(path)[1] or '.png'
        ok, buf = cv2.imencode(ext, img)
        if ok:
            buf.tofile(path)
            return True
    except:
        pass
    return False

# å®šä¹‰ä¸€ä¸ªåªåš ToTensor å’Œ Normalize çš„ transformï¼Œä¿ç•™åŸå°ºå¯¸
def get_raw_transforms():
    return transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
# ==========================================
# 2. æ¨ç†å¼•æ“ (æ•´å›¾æ¨ç†)
# ==========================================

class PaDiMInferenceEngine:
    def __init__(self, model_dir, device='cuda'):
        from models.padim_detector import PaDiMDetector
        
        print(f"ğŸ—ï¸  åŠ è½½æ¨¡å‹: {model_dir}")
        self.detector = PaDiMDetector(model_dir=model_dir)
        self.device = device
        
        self.transform = transforms.Compose([
            transforms.Resize((112, 112)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])

    def process_folder(self, input_dir, save_dir, threshold=15):
        # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(input_dir):
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return
        valid_exts = {'.jpg', '.jpeg', '.png', '.bmp'}
        files = [f for f in os.listdir(input_dir) if os.path.splitext(f)[1].lower() in valid_exts]
        if not files:
            print("âš ï¸ æ–‡ä»¶å¤¹ä¸ºç©º")
            return
        print(f"ğŸš€ å¼€å§‹å¤„ç† {len(files)} å¼ å›¾ç‰‡...")
        os.makedirs(save_dir, exist_ok=True)
        
        # é¢„çƒ­ GPU
        print("ğŸ”¥ æ­£åœ¨é¢„çƒ­ GPU...")
        dummy = torch.randn(1, 3, 112, 112).to(self.device)  # ç¡®ä¿å°ºå¯¸ä¸º 112Ã—112
        for _ in range(5): self.detector.predict(dummy)
        torch.cuda.synchronize()

        t_start = time.perf_counter()
        
        for idx, f in enumerate(files):
            img_path = os.path.join(input_dir, f)
            img_bgr = cv_imread(img_path)
            if img_bgr is None: 
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {img_path}")
                continue
            
            # 1. é¢„å¤„ç†
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(img_rgb)
            input_tensor = self.transform(pil_img).unsqueeze(0).to(self.device)
            
            # 2. æ¨ç†
            amap, score = self.detector.predict(input_tensor)
            score = score[0]
            amap = amap[0]  # (H, W) åŸå§‹å¼‚å¸¸å€¼
            
            # 3. æ‰“å°çŠ¶æ€
            status = "ğŸ”´å¼‚å¸¸" if score > threshold else "ğŸŸ¢æ­£å¸¸"
            print(f"[{idx+1}/{len(files)}] {f} -> {status} (å¾—åˆ†: {score:.2f})")
            
            # ==========================================
            # 4. çƒ­åŠ›å›¾ç”Ÿæˆ (Matplotlib 4å­å›¾æ ·å¼ï¼Œå»é™¤é»‘ç™½å›¾)
            # ==========================================
            import matplotlib.pyplot as plt
            
            # Resize å¼‚å¸¸å›¾åˆ°åŸå›¾å¤§å°
            amap_resized = cv2.resize(amap, (img_bgr.shape[1], img_bgr.shape[0]))
            
            # --- A. å‡†å¤‡æ•°æ® ---
            # å±€éƒ¨å½’ä¸€åŒ– (ä»…å±•ç¤ºå½“å‰å›¾å†…éƒ¨çš„ç›¸å¯¹å¼ºå¼±)
            local_min, local_max = amap_resized.min(), amap_resized.max()
            local_norm = (amap_resized - local_min) / (local_max - local_min + 1e-8)
            
            # å…¨å±€å½’ä¸€åŒ– (ä½¿ç”¨ threshold ä½œä¸ºåŸºå‡†)
            g_min, g_max = 0, threshold
            global_norm = np.clip((amap_resized - g_min) / (g_max - g_min + 1e-8), 0, 1)
            
            # --- B. ç»˜å›¾ (2x2 å¸ƒå±€) ---
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
            
            # 1. åŸå›¾
            ax1.imshow(img_rgb)
            ax1.set_title(f'Original Image\n{f}', fontsize=12)
            ax1.axis('off')
            
            # 2. å±€éƒ¨å½’ä¸€åŒ–çƒ­åŠ›å›¾
            im2 = ax2.imshow(local_norm, cmap='jet', vmin=0, vmax=1)
            ax2.set_title(f'Local Normalized Heatmap\nRange: [{local_min:.3f}, {local_max:.3f}]', fontsize=12)
            ax2.axis('off')
            plt.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)
            
            # 3. å…¨å±€å½’ä¸€åŒ–çƒ­åŠ›å›¾
            im3 = ax3.imshow(global_norm, cmap='jet', vmin=0, vmax=1)
            ax3.set_title(f'Global Normalized Heatmap\nRef Range: [0, {threshold}]', fontsize=12)
            ax3.axis('off')
            plt.colorbar(im3, ax=ax3, fraction=0.046, pad=0.04)
            
            # 4. å åŠ æ˜¾ç¤º (Overlay)
            ax4.imshow(img_rgb)
            im4 = ax4.imshow(global_norm, cmap='jet', alpha=0.5, vmin=0, vmax=1)
            ax4.set_title(f'Overlay (Global Norm)\nScore: {score:.4f} | Status: {status}', fontsize=12)
            ax4.axis('off')
            plt.colorbar(im4, ax=ax4, fraction=0.046, pad=0.04)
            
            # --- C. ä¿å­˜ ---
            save_name = os.path.splitext(f)[0] + '_analysis.png'
            
            # ä¿å­˜åˆ° detection_heatmaps å­æ–‡ä»¶å¤¹
            heatmap_dir = os.path.join(save_dir, 'detection_heatmaps')
            os.makedirs(heatmap_dir, exist_ok=True)
            
            save_path = os.path.join(heatmap_dir, save_name)
            plt.savefig(save_path, bbox_inches='tight', dpi=100, facecolor='white')
            plt.close(fig) # å…³é—­å›¾å½¢é‡Šæ”¾å†…å­˜

        t_end = time.perf_counter()
        avg_time = (t_end - t_start) / len(files) * 1000
        print(f"âœ… å…¨éƒ¨å®Œæˆ | å¹³å‡è€—æ—¶: {avg_time:.2f} ms/å¼ ")


# ==========================================
# 3. ä¸»å…¥å£
# ==========================================

def main(args):
    try:
        # åˆå§‹åŒ–å¼•æ“
        engine = PaDiMInferenceEngine(args.model_dir)
        
        # æ‰§è¡Œæ¨ç†
        engine.process_folder(
            input_dir=args.test_data, 
            save_dir=args.save_dir, 
            threshold=args.threshold
        )
            
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="PaDiM Inference (Full Image)")
    
    parser.add_argument('--model_dir', type=str, required=True, help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--test_data', type=str, required=True, help='æµ‹è¯•æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--save_dir', type=str, default='./results', help='ç»“æœä¿å­˜è·¯å¾„')
    parser.add_argument('--threshold', type=float, default=15.0, help='å¼‚å¸¸é˜ˆå€¼')
    
    args = parser.parse_args()
    main(args)